{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yilong/miniconda3/envs/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ds3 = load_dataset('parquet', data_files='../data/kk/instruct/3ppl/train.parquet')['train']\n",
    "train_test_ds4 = load_dataset('parquet', data_files='../data/kk/instruct/4ppl/train.parquet')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quiz</th>\n",
       "      <th>names</th>\n",
       "      <th>knight_knave</th>\n",
       "      <th>solution</th>\n",
       "      <th>solution_text</th>\n",
       "      <th>solution_text_format</th>\n",
       "      <th>cot_head</th>\n",
       "      <th>cot_repeat_steps</th>\n",
       "      <th>cot_foot</th>\n",
       "      <th>statements</th>\n",
       "      <th>index</th>\n",
       "      <th>data_source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ability</th>\n",
       "      <th>reward_model</th>\n",
       "      <th>extra_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very special island is inhabited only by kni...</td>\n",
       "      <td>[Michael, Zoey, Ethan]</td>\n",
       "      <td>{'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...</td>\n",
       "      <td>[True, True, True]</td>\n",
       "      <td>Michael is a knight, Zoey is a knight, and Eth...</td>\n",
       "      <td>(1) Michael is a knight\\n(2) Zoey is a knight\\...</td>\n",
       "      <td>Let's think step by step, by considering wheth...</td>\n",
       "      <td>[Assume Michael is a knight. No contradiction ...</td>\n",
       "      <td>This leads to a feasible solution.</td>\n",
       "      <td>(('&lt;=&gt;', ('telling-truth', 2), ('telling-truth...</td>\n",
       "      <td>100</td>\n",
       "      <td>kk_logic</td>\n",
       "      <td>[{'content': '&lt;|im_start|&gt;system\n",
       "You are a hel...</td>\n",
       "      <td>logic</td>\n",
       "      <td>{'ground_truth': {'solution_text_format': '(1)...</td>\n",
       "      <td>{'index': 0, 'split': 'train'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A very special island is inhabited only by kni...</td>\n",
       "      <td>[Michael, Mason, Jacob]</td>\n",
       "      <td>{'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...</td>\n",
       "      <td>[True, False, True]</td>\n",
       "      <td>Michael is a knight, Mason is a knave, and Jac...</td>\n",
       "      <td>(1) Michael is a knight\\n(2) Mason is a knave\\...</td>\n",
       "      <td>Let's think step by step, by considering wheth...</td>\n",
       "      <td>[Assume Michael is a knight. No contradiction ...</td>\n",
       "      <td>This leads to a feasible solution.</td>\n",
       "      <td>(('not', ('telling-truth', 1)), ('and', ('tell...</td>\n",
       "      <td>101</td>\n",
       "      <td>kk_logic</td>\n",
       "      <td>[{'content': '&lt;|im_start|&gt;system\n",
       "You are a hel...</td>\n",
       "      <td>logic</td>\n",
       "      <td>{'ground_truth': {'solution_text_format': '(1)...</td>\n",
       "      <td>{'index': 1, 'split': 'train'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quiz                    names  \\\n",
       "0  A very special island is inhabited only by kni...   [Michael, Zoey, Ethan]   \n",
       "1  A very special island is inhabited only by kni...  [Michael, Mason, Jacob]   \n",
       "\n",
       "                                        knight_knave             solution  \\\n",
       "0  {'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...   [True, True, True]   \n",
       "1  {'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...  [True, False, True]   \n",
       "\n",
       "                                       solution_text  \\\n",
       "0  Michael is a knight, Zoey is a knight, and Eth...   \n",
       "1  Michael is a knight, Mason is a knave, and Jac...   \n",
       "\n",
       "                                solution_text_format  \\\n",
       "0  (1) Michael is a knight\\n(2) Zoey is a knight\\...   \n",
       "1  (1) Michael is a knight\\n(2) Mason is a knave\\...   \n",
       "\n",
       "                                            cot_head  \\\n",
       "0  Let's think step by step, by considering wheth...   \n",
       "1  Let's think step by step, by considering wheth...   \n",
       "\n",
       "                                    cot_repeat_steps  \\\n",
       "0  [Assume Michael is a knight. No contradiction ...   \n",
       "1  [Assume Michael is a knight. No contradiction ...   \n",
       "\n",
       "                             cot_foot  \\\n",
       "0  This leads to a feasible solution.   \n",
       "1  This leads to a feasible solution.   \n",
       "\n",
       "                                          statements  index data_source  \\\n",
       "0  (('<=>', ('telling-truth', 2), ('telling-truth...    100    kk_logic   \n",
       "1  (('not', ('telling-truth', 1)), ('and', ('tell...    101    kk_logic   \n",
       "\n",
       "                                              prompt ability  \\\n",
       "0  [{'content': '<|im_start|>system\n",
       "You are a hel...   logic   \n",
       "1  [{'content': '<|im_start|>system\n",
       "You are a hel...   logic   \n",
       "\n",
       "                                        reward_model  \\\n",
       "0  {'ground_truth': {'solution_text_format': '(1)...   \n",
       "1  {'ground_truth': {'solution_text_format': '(1)...   \n",
       "\n",
       "                       extra_info  \n",
       "0  {'index': 0, 'split': 'train'}  \n",
       "1  {'index': 1, 'split': 'train'}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfkk3 = pd.DataFrame(train_test_ds3)\n",
    "dfkk3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quiz</th>\n",
       "      <th>names</th>\n",
       "      <th>knight_knave</th>\n",
       "      <th>solution</th>\n",
       "      <th>solution_text</th>\n",
       "      <th>solution_text_format</th>\n",
       "      <th>cot_head</th>\n",
       "      <th>cot_repeat_steps</th>\n",
       "      <th>cot_foot</th>\n",
       "      <th>statements</th>\n",
       "      <th>index</th>\n",
       "      <th>data_source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>ability</th>\n",
       "      <th>reward_model</th>\n",
       "      <th>extra_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very special island is inhabited only by kni...</td>\n",
       "      <td>[Ethan, Abigail, David, Noah]</td>\n",
       "      <td>{'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...</td>\n",
       "      <td>[False, True, True, True]</td>\n",
       "      <td>Ethan is a knave, Abigail is a knight, David i...</td>\n",
       "      <td>(1) Ethan is a knave\\n(2) Abigail is a knight\\...</td>\n",
       "      <td>Let's think step by step, by considering wheth...</td>\n",
       "      <td>[Assume Ethan is a knight. No contradiction is...</td>\n",
       "      <td>This leads to a feasible solution.</td>\n",
       "      <td>(('or', ('lying', 2), ('lying', 1)), ('-&gt;', ('...</td>\n",
       "      <td>100</td>\n",
       "      <td>kk_logic</td>\n",
       "      <td>[{'content': '&lt;|im_start|&gt;system\n",
       "You are a hel...</td>\n",
       "      <td>logic</td>\n",
       "      <td>{'ground_truth': {'solution_text_format': '(1)...</td>\n",
       "      <td>{'index': 0, 'split': 'train'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A very special island is inhabited only by kni...</td>\n",
       "      <td>[Elizabeth, Sophia, Mason, Abigail]</td>\n",
       "      <td>{'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...</td>\n",
       "      <td>[True, False, False, False]</td>\n",
       "      <td>Elizabeth is a knight, Sophia is a knave, Maso...</td>\n",
       "      <td>(1) Elizabeth is a knight\\n(2) Sophia is a kna...</td>\n",
       "      <td>Let's think step by step, by considering wheth...</td>\n",
       "      <td>[Assume Elizabeth is a knight. No contradictio...</td>\n",
       "      <td>This leads to a feasible solution.</td>\n",
       "      <td>(('and', ('lying', 3), ('lying', 2)), ('-&gt;', (...</td>\n",
       "      <td>101</td>\n",
       "      <td>kk_logic</td>\n",
       "      <td>[{'content': '&lt;|im_start|&gt;system\n",
       "You are a hel...</td>\n",
       "      <td>logic</td>\n",
       "      <td>{'ground_truth': {'solution_text_format': '(1)...</td>\n",
       "      <td>{'index': 1, 'split': 'train'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quiz  \\\n",
       "0  A very special island is inhabited only by kni...   \n",
       "1  A very special island is inhabited only by kni...   \n",
       "\n",
       "                                 names  \\\n",
       "0        [Ethan, Abigail, David, Noah]   \n",
       "1  [Elizabeth, Sophia, Mason, Abigail]   \n",
       "\n",
       "                                        knight_knave  \\\n",
       "0  {'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...   \n",
       "1  {'Knave': 'Knave', 'Knight': 'Knight', 'a_knav...   \n",
       "\n",
       "                      solution  \\\n",
       "0    [False, True, True, True]   \n",
       "1  [True, False, False, False]   \n",
       "\n",
       "                                       solution_text  \\\n",
       "0  Ethan is a knave, Abigail is a knight, David i...   \n",
       "1  Elizabeth is a knight, Sophia is a knave, Maso...   \n",
       "\n",
       "                                solution_text_format  \\\n",
       "0  (1) Ethan is a knave\\n(2) Abigail is a knight\\...   \n",
       "1  (1) Elizabeth is a knight\\n(2) Sophia is a kna...   \n",
       "\n",
       "                                            cot_head  \\\n",
       "0  Let's think step by step, by considering wheth...   \n",
       "1  Let's think step by step, by considering wheth...   \n",
       "\n",
       "                                    cot_repeat_steps  \\\n",
       "0  [Assume Ethan is a knight. No contradiction is...   \n",
       "1  [Assume Elizabeth is a knight. No contradictio...   \n",
       "\n",
       "                             cot_foot  \\\n",
       "0  This leads to a feasible solution.   \n",
       "1  This leads to a feasible solution.   \n",
       "\n",
       "                                          statements  index data_source  \\\n",
       "0  (('or', ('lying', 2), ('lying', 1)), ('->', ('...    100    kk_logic   \n",
       "1  (('and', ('lying', 3), ('lying', 2)), ('->', (...    101    kk_logic   \n",
       "\n",
       "                                              prompt ability  \\\n",
       "0  [{'content': '<|im_start|>system\n",
       "You are a hel...   logic   \n",
       "1  [{'content': '<|im_start|>system\n",
       "You are a hel...   logic   \n",
       "\n",
       "                                        reward_model  \\\n",
       "0  {'ground_truth': {'solution_text_format': '(1)...   \n",
       "1  {'ground_truth': {'solution_text_format': '(1)...   \n",
       "\n",
       "                       extra_info  \n",
       "0  {'index': 0, 'split': 'train'}  \n",
       "1  {'index': 1, 'split': 'train'}  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfkk4 = pd.DataFrame(train_test_ds4)\n",
    "dfkk4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 3ppl:900\n",
      "len 4ppl:900\n"
     ]
    }
   ],
   "source": [
    "print('len 3ppl:{}\\nlen 4ppl:{}'.format(len(dfkk3), len(dfkk4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkk = pd.concat([dfkk3, dfkk4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.  Now the user asks you to solve a logical reasoning problem. After thinking, when you finally reach a conclusion, clearly state the identity of each character within <answer> </answer> tags. i.e., <answer> (1) Zoey is a knight\n",
      "(2) ... </answer>.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. You meet 3 inhabitants: Michael, Zoey, and Ethan. Michael was heard saying, \"Ethan is a knight if and only if Michael is a knight\". \"Zoey is a knight or Ethan is a knight,\" Zoey mentioned. Ethan asserted: \"Michael is a knave if and only if Zoey is a knave\". So who is a knight and who is a knave?\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "print(dfkk.prompt[0][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfk = dfkk.loc[:, ['ability']].copy()\n",
    "dfk['story']=dfkk.quiz\n",
    "dfk['answer']=dfkk.solution_text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(x, i):\n",
    "    data = { # type: ignore\n",
    "            'prompt': [\n",
    "                {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                {'role': 'user', 'content': x['story']}\n",
    "            ],\n",
    "            'answer': x['answer']\n",
    "        }\n",
    "    return data\n",
    "prompt = []\n",
    "\n",
    "\n",
    "for i, row in dfk.iterrows():\n",
    "    prompt.append([\n",
    "                {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "                {'role': 'user', 'content': row['story']+'Clearly state the identity of each character in answer. i.e., (1) character_name is a character_identity (2) ... '}\n",
    "            ])\n",
    "\n",
    "dfk['prompt']=prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>story</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logic</td>\n",
       "      <td>A very special island is inhabited only by kni...</td>\n",
       "      <td>(1) Michael is a knight\\n(2) Zoey is a knight\\...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logic</td>\n",
       "      <td>A very special island is inhabited only by kni...</td>\n",
       "      <td>(1) Michael is a knight\\n(2) Mason is a knave\\...</td>\n",
       "      <td>[{'role': 'system', 'content': 'You are a help...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ability                                              story  \\\n",
       "0   logic  A very special island is inhabited only by kni...   \n",
       "1   logic  A very special island is inhabited only by kni...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  (1) Michael is a knight\\n(2) Zoey is a knight\\...   \n",
       "1  (1) Michael is a knight\\n(2) Mason is a knave\\...   \n",
       "\n",
       "                                              prompt  \n",
       "0  [{'role': 'system', 'content': 'You are a help...  \n",
       "1  [{'role': 'system', 'content': 'You are a help...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfk.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(list(map(lambda x: len(x.split()), dfk.story)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A very special island is inhabited only by knights and knaves. Knights always tell the truth, and knaves always lie. You meet 3 inhabitants: Michael, Zoey, and Ethan. Michael was heard saying, \"Ethan is a knight if and only if Michael is a knight\". \"Zoey is a knight or Ethan is a knight,\" Zoey mentioned. Ethan asserted: \"Michael is a knave if and only if Zoey is a knave\". So who is a knight and who is a knave?Clearly state the identity of each character in answer. i.e., (1) character_name is a character_identity (2) ... \n",
      "(1) Michael is a knight\n",
      "(2) Zoey is a knight\n",
      "(3) Ethan is a knight\n"
     ]
    }
   ],
   "source": [
    "print(dfk.prompt[0][1]['content'])\n",
    "print(dfk.answer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nt = load_dataset('parquet', data_files='cleaned_train_nt_with_structure_384.parquet')['train']\n",
    "train_ft = load_dataset('parquet', data_files='cleaned_train_ft_with_structure_384.parquet')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a helpful assistant. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.',\n",
       "  'role': 'system'},\n",
       " {'content': 'Story: The tourist information center, a cozy hub of local knowledge and traveler activity, stood ready to serve as a central gathering point. Its warm wooden accents and large windows provided a welcoming atmosphere amidst the bustling downtown area. Two familiar faces, Abigail and Andrew, converged on the tourist information center, bringing with them their unique expertise and infectious enthusiasm for the local scene. Abigail\\'s voice carried through the center, weaving a vivid tapestry of local treasures, including the iconic lighthouse and the quaint seaside promenade. As she spoke, her eyes sparkled with an unmistakable passion for the area\\'s rich history and hidden gems. Tristan walked into the tourist information center a moment after Alexis, and the sound of Abigail\\'s voice greeting visitors filled the warm space they now shared. Alexis\\'s voice wove in and out of Abigail\\'s, adding a new layer of depth to the conversation as she described the way the festival would be set up. Andrew spoke up, \"Handmade candles with the scent of sea salt and driftwood, or how about painted seashells as ornaments – these unique souvenirs will transport our customers back to this enchanting coastline.\" His voice was filled with excitement as he presented his ideas to anyone who would listen.\\n Question:What does Abigail think about Alexis\\'s belief on festival venue layout? (knows about it / does not know about it)',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nt['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a helpful assistant. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.',\n",
       "  'role': 'system'},\n",
       " {'content': \"Story: Lauren entered the back room of the coffee shop. Anthony entered the back room of the coffee shop. Lauren moved the bag of gourmet coffee beans to the wooden crate, which is also located in the back room of the coffee shop. Anthony moved the bag of gourmet coffee beans to the canvas tote bag, which is also located in the back room of the coffee shop. Lauren placed a label that says 'decaf' on the bag of gourmet coffee beans Lauren moved the bag of gourmet coffee beans to the cardboard box, which is also located in the back room of the coffee shop.\\n Question:In which container is the bag of gourmet coffee beans now?\",\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ft['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnt = pd.DataFrame(train_nt)\n",
    "dfft = pd.DataFrame(train_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5722"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5722 1584 791 0\n",
      "What does Abigail think about Alexis's belief on festival venue layout? (knows about it / does not know about it)\n",
      "Does Abigail think that Jasmine believes that the silver letter opener has a microscopic identification code etched at the base of the handle? Answer yes or no.\n",
      "In which room does Abigail think that Alexis will search for the leather briefcase?\n"
     ]
    }
   ],
   "source": [
    "print(len(dfnt), len(dfnt.loc[dfnt.answer.isin(['yes'])]), len(dfnt.loc[dfnt.answer.isin(['knows about it'])]), len(dfnt.loc[dfnt.answer.isin(['does not know about it'])]))\n",
    "print(dfnt.loc[dfnt.answer.isin(['knows about it'])]['question'].values[0])\n",
    "print(dfnt.loc[dfnt.answer.isin(['yes'])]['question'].values[0])\n",
    "print(dfnt.loc[~dfnt.answer.isin(['knows about it', 'yes'])]['question'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NT = 300\n",
    "NT_yes = 20\n",
    "NT_know = 20\n",
    "FT = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.concat([\n",
    "    dfnt.loc[dfnt.answer.isin(['yes'])].sample(n = NT_yes, replace=False, ignore_index=True, random_state=42),\n",
    "    dfnt.loc[dfnt.answer.isin(['knows about it'])].sample(n = NT_know, replace=False, ignore_index=True, random_state=42),\n",
    "    dfnt.loc[~dfnt.answer.isin(['knows about it', 'yes'])].sample(n = NT-NT_know-NT_yes, replace=False, ignore_index=True, random_state=42),\n",
    "    ],\n",
    "    ignore_index=True)\n",
    "dff = dfft.sample(n = FT, replace=False, ignore_index=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dfk, dfn.loc[:, ['ability', 'story', 'answer', 'prompt']], dff.loc[:, ['ability', 'story', 'answer', 'prompt']] ])\n",
    "df = df.sample(frac=1, replace=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('ToM_KK_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ability', 'story', 'answer', 'prompt'],\n",
       "    num_rows: 3800\n",
       "})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 416.31ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4972263"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_parquet('ToM_KK_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.concat([dfn.loc[:, ['ability', 'story', 'answer', 'prompt']], dff.loc[:, ['ability', 'story', 'answer', 'prompt']] ])\n",
    "dft = dft.sample(frac=1, replace=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(dft.story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2000 examples [00:00, 184645.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_tom = load_dataset('parquet', data_files='ToM_2k.parquet')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tom = pd.DataFrame(data_tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = (df_tom.groupby('answer').story.count()/len(df_tom)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>does not know about it</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>knows about it</td>\n",
       "      <td>0.1725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>no</td>\n",
       "      <td>0.0635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>plastic storage bin</td>\n",
       "      <td>0.0225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>yes</td>\n",
       "      <td>0.1630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     answer   story\n",
       "39   does not know about it  0.2925\n",
       "52           knows about it  0.1725\n",
       "73                       no  0.0635\n",
       "81      plastic storage bin  0.0225\n",
       "101                     yes  0.1630"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.loc[ans.story>0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.loc[ans.story>0.02].story.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.loc[ans.story>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
